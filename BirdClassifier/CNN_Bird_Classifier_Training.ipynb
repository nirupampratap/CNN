{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bird Classifier - Training the model\n",
    "#### Notebook Author: Nirupam Purushothama\n",
    "\n",
    "This notebook trains a CNN to identify if a given image contains a bird or not. \n",
    "\n",
    "Refer to my TensorFlow notes before you proceed with this notebook. This notebook will not explain the details relating to how CNN works and what pooling, kernel-sizes, padding etc. are. You can refer to the medium-blog I provided below, it gives you an intuition behind Convolution Neural Networks, but for complete details you will need to understand TensorFlow better (At least for one basic model)\n",
    "\n",
    "#### System requirement:\n",
    "1. Memory: Minimum 16GB RAM.\n",
    "2. Takes 5 hours to finish the training run. You can speed it up by using graphics card processors etc. Refer to the article mentioned below.\n",
    "\n",
    "#### Tips\n",
    "1. If you are just using this notebook for learning purposes then a couple of places where you can get free credits are AWS Educate and Azure Student credits. As on March 2019, Azure gives you $\\$100$ credit and AWS Educate (via [GitHub Education](https://education.github.com/students)) gets you $\\$150$ credit. Both are for one year and six months respectively. Azure activation is immediate and GitHub verification takes 3-5 days.\n",
    "2. These credits are not much. But should be able to let you run some heavy duty notebooks like these.\n",
    "\n",
    "#### References: \n",
    "1. Machine Learning is Fun - Part 3 - [Medium Blog](https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721)\n",
    "2. Datasets \n",
    "    * [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html), Contains 6,000 birds and 52,000 other objects\n",
    "    * [Caltech-UCSD Birds-200-2011 dataset](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html), Contains 12,000 birds\n",
    "    * Full data is available [here](https://s3-us-west-2.amazonaws.com/ml-is-fun/data.zip)\n",
    "3. Uses TFLearn (Framework on top of TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "# Import tflearn and some helpers\n",
    "import tflearn\n",
    "from tflearn.data_utils import shuffle\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set\n",
    "# Blog author made the dataset available here: \n",
    "# https://s3-us-west-2.amazonaws.com/ml-is-fun/data.zip\n",
    "\n",
    "# The original code has a problem with loading (at least on my machine. Hence had to modify it accordingly)\n",
    "\n",
    "with open(\"../../data/full_dataset.pkl\", 'rb') as f:\n",
    "    X, Y, X_test, Y_test = pickle.load(f, encoding='latin1')\n",
    "\n",
    "# Shuffle the data\n",
    "X, Y = shuffle(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just a small bit of info about tflearn\n",
    "I looked at the documentation and it was devoid of any explanations and it is pretty lame. But if you are comfortable with tensorflow then understanding tflearn is not a big deal. You can infer stuff from the method signatures in the documentation. But obviously it is not so user-friendly. \n",
    "\n",
    "I can understand tensor-flow at this time and understanding tflearn is not a problem. But given the state of its documentation I think the more prudent thing will be to migrate to Keras in the future. But there are some concerns raised on the speed of Keras as it is a more generic framework on top of tensor-flow (because it can support more platforms like Theano and Microsoft's CNTK). Among these Theano is [dead](https://skymind.ai/wiki/comparison-frameworks-dl4j-tensorflow-pytorch#theano). And I am damn sure that Microsoft's CNTK (although open-source) doesn't stand a chance before other purely open-source frameworks. But despite this, Keras is already more popular, easy to use and has a lot of examples floating around. So, I will move to Keras after these examples. But I already like TFLearn. Hence, I will keep checking TFlearn once in a while to see if it is making stronger progress than Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the data is normalized\n",
    "img_prep = ImagePreprocessing()\n",
    "img_prep.add_featurewise_zero_center()\n",
    "img_prep.add_featurewise_stdnorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extra synthetic training data by flipping, rotating and blurring the images on our data set.\n",
    "img_aug = ImageAugmentation()\n",
    "img_aug.add_random_flip_leftright()\n",
    "img_aug.add_random_rotation(max_angle=25.)\n",
    "img_aug.add_random_blur(sigma_max=3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the network\n",
    "<b>Note:</b>  This is super-cool and awesome. Doing the same thing with Tensorflow would be super tedious. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nirupam/anaconda3/lib/python3.6/site-packages/tflearn/initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n"
     ]
    }
   ],
   "source": [
    "# Define our network architecture:\n",
    "\n",
    "# Input is a 32x32 image with 3 color channels (red, green and blue)\n",
    "network = input_data(shape=[None, 32, 32, 3],\n",
    "                     data_preprocessing=img_prep,\n",
    "                     data_augmentation=img_aug)\n",
    "\n",
    "# Step 1: Convolution - Num_Convulution_filters: 32, kernel_filter_size = 3x3\n",
    "network = conv_2d(network, 32, 3, activation='relu')\n",
    "\n",
    "# Step 2: Max pooling - Kernel size\n",
    "network = max_pool_2d(network, 2)\n",
    "\n",
    "# Step 3: Convolution again\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "\n",
    "# Step 4: Convolution yet again\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "\n",
    "# Step 5: Max pooling again\n",
    "network = max_pool_2d(network, 2)\n",
    "\n",
    "# Step 6: Fully-connected 512 node neural network\n",
    "network = fully_connected(network, 512, activation='relu')\n",
    "\n",
    "# Step 7: Dropout - throw away some data randomly during training to prevent over-fitting\n",
    "network = dropout(network, 0.5)\n",
    "\n",
    "# Step 8: Fully-connected neural network with two outputs (0=isn't a bird, 1=is a bird) to make the final prediction\n",
    "network = fully_connected(network, 2, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Again it is awesome. The same stuff in TensorFlow would have been a pain to setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 59199  | total loss: \u001b[1m\u001b[32m0.17229\u001b[0m\u001b[0m | time: 262.484s\n",
      "| Adam | epoch: 100 | loss: 0.17229 - acc: 0.9298 -- iter: 56736/56780\n",
      "Training Step: 59200  | total loss: \u001b[1m\u001b[32m0.17152\u001b[0m\u001b[0m | time: 286.752s\n",
      "| Adam | epoch: 100 | loss: 0.17152 - acc: 0.9296 | val_loss: 0.18057 - val_acc: 0.9483 -- iter: 56780/56780\n",
      "--\n",
      "INFO:tensorflow:/home/nirupam/learning/CNN_ImageAnalysis/BirdClassifier/bird-classifier.tfl.ckpt-59200 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "# Tell tflearn how we want to train the network\n",
    "network = regression(network, optimizer='adam',\n",
    "                     loss='categorical_crossentropy', learning_rate=0.001)\n",
    "\n",
    "# Wrap the network in a model object\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0, checkpoint_path='bird-classifier.tfl.ckpt')\n",
    "\n",
    "# Train it! We'll do 100 training passes and monitor it as it goes.\n",
    "model.fit(X, Y, n_epoch=100, shuffle=True, validation_set=(X_test, Y_test),\n",
    "          show_metric=True, batch_size=96,\n",
    "          snapshot_epoch=True, run_id='bird-classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/home/nirupam/learning/CNN_ImageAnalysis/BirdClassifier/bird-classifier.tfl is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Network trained and saved as bird-classifier.tfl!\n"
     ]
    }
   ],
   "source": [
    "# Save model when training is complete to a file\n",
    "model.save(\"./bird-classifier.tfl\")\n",
    "print(\"Network trained and saved as bird-classifier.tfl!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
